[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 bolasso authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Molitor. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Molitor D (2024). bolasso: Model Consistent Lasso Estimation Bootstrap. R package version 0.3.0, https://github.com/dmolitor/bolasso, https://www.dmolitor.com/bolasso/.","code":"@Manual{,   title = {bolasso: Model Consistent Lasso Estimation Through the Bootstrap},   author = {Daniel Molitor},   year = {2024},   note = {R package version 0.3.0, https://github.com/dmolitor/bolasso},   url = {https://www.dmolitor.com/bolasso/}, }"},{"path":"/index.html","id":"bolasso-","dir":"","previous_headings":"","what":"Model Consistent Lasso Estimation Through the Bootstrap","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"goal bolasso implement bootstrap-enhanced Lasso (generally, penalized regression) estimation, proposed originally Bach (2008) extended Bunea et al.¬†(2011) Abram et al.¬†(2016). methods focus primarily variable selection propose two similar, slightly different, variable selection algorithms; variable inclusion probability (VIP) algorithm (Bach; Bunea et al.), bootstrap distribution quantile (QNT) algorithm (Abram et al.). Beyond implementing variable selection methods, bolasso also provides utilities making bagged predictions, examining coefficient distributions, plotting.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"Install bolasso CRAN: install development version GitHub :","code":"install.packages(\"bolasso\") # install.packages(\"pak\") pak::pkg_install(\"dmolitor/bolasso@dev\")"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"illustrate usage bolasso, ‚Äôll use Pima Indians Diabetes dataset determine factors important predictors testing positive diabetes. full description input variables, see link .","code":""},{"path":"/index.html","id":"load-requisite-packages-and-data","dir":"","previous_headings":"Usage","what":"Load requisite packages and data","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"First, let‚Äôs create train/test split data, run 100-fold bootstrapped Lasso glmnet.","code":"library(bolasso) library(ggplot2) library(tibble)  data(PimaIndiansDiabetes, package = \"mlbench\")  # Quick overview of the dataset str(PimaIndiansDiabetes) #> 'data.frame':    768 obs. of  9 variables: #>  $ pregnant: num  6 1 8 1 0 5 3 10 2 8 ... #>  $ glucose : num  148 85 183 89 137 116 78 115 197 125 ... #>  $ pressure: num  72 66 64 66 40 74 50 0 70 96 ... #>  $ triceps : num  35 29 0 23 35 0 32 0 45 0 ... #>  $ insulin : num  0 0 0 94 168 0 88 0 543 0 ... #>  $ mass    : num  33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 0 ... #>  $ pedigree: num  0.627 0.351 0.672 0.167 2.288 ... #>  $ age     : num  50 31 32 21 33 30 26 29 53 54 ... #>  $ diabetes: Factor w/ 2 levels \"neg\",\"pos\": 2 1 2 1 2 1 2 1 2 2 ... train_idx <- sample(1:nrow(PimaIndiansDiabetes), round(0.7*nrow(PimaIndiansDiabetes))) train <- PimaIndiansDiabetes[train_idx, ] test <- PimaIndiansDiabetes[-train_idx, ]  model <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\" ) #> Loaded glmnet 4.1-8"},{"path":"/index.html","id":"variable-selection","dir":"","previous_headings":"Usage","what":"Variable selection","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"Next, using threshold 0.95 can extract selected variables using VIP method, extracts variables selected (non-zero coefficients) >= 95% bootstrapped models. ‚Äôll use regularization parameter lambda.min minimizes cross-validation error. Note returned tibble selected variables columns coefficients bootstrapped models rows. want simply return variable names, can add var_names_only argument: can compare selected variables using VIP method QNT method, selects variables 95% bootstrap confidence interval contain 0: Note number selected variables QNT always <= VIP. default method bolasso method = \"vip\".","code":"selected_variables(model, threshold = 0.95, method = \"vip\", select = \"lambda.min\") #> # A tibble: 100 √ó 5 #>    id     pregnant glucose   mass    age #>    <chr>     <dbl>   <dbl>  <dbl>  <dbl> #>  1 boot1    0.117   0.0384 0.0800 0.0145 #>  2 boot2    0.112   0.0331 0.0675 0.0115 #>  3 boot3    0.143   0.0257 0.112  0.0135 #>  4 boot4    0.130   0.0240 0.0789 0.0240 #>  5 boot5    0.0473  0.0215 0.0793 0.0183 #>  6 boot6    0.0634  0.0247 0.0666 0.0346 #>  7 boot7    0.101   0.0326 0.0656 0.0194 #>  8 boot8    0.0761  0.0258 0.0937 0.0359 #>  9 boot9    0.202   0.0238 0.0613 0.0113 #> 10 boot10   0.0926  0.0337 0.0779 0.0293 #> # ‚Ñπ 90 more rows selected_variables(model, 0.95, \"vip\", var_names_only = TRUE) #> [1] \"pregnant\" \"glucose\"  \"mass\"     \"age\" selected_variables(model, 0.95, \"qnt\", var_names_only = TRUE) #> [1] \"pregnant\" \"glucose\"  \"mass\""},{"path":"/index.html","id":"variable-selection-thresholds","dir":"","previous_headings":"Usage > Variable selection","what":"Variable selection thresholds","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"may , instead selecting variables given threshold method, want see largest threshold variable selected VIP QNT methods. can quickly visualize plot_selection_thresholds function.  can also get thresholds tibble:","code":"plot_selection_thresholds(model, select = \"lambda.min\") selection_thresholds(model, select = \"lambda.min\") #> # A tibble: 16 √ó 5 #>    covariate method threshold  alpha covariate_id #>    <chr>     <chr>      <dbl>  <dbl>        <int> #>  1 age       QNT         0.93 0.0700            8 #>  2 glucose   QNT         1    0                 2 #>  3 insulin   QNT         0.39 0.61              5 #>  4 mass      QNT         1    0                 6 #>  5 pedigree  QNT         0.77 0.23              7 #>  6 pregnant  QNT         1    0                 1 #>  7 pressure  QNT         0.65 0.35              3 #>  8 triceps   QNT         0    1                 4 #>  9 age       VIP         0.97 0.0300            8 #> 10 glucose   VIP         1    0                 2 #> 11 insulin   VIP         0.78 0.22              5 #> 12 mass      VIP         1    0                 6 #> 13 pedigree  VIP         0.9  0.1               7 #> 14 pregnant  VIP         1    0                 1 #> 15 pressure  VIP         0.84 0.16              3 #> 16 triceps   VIP         0.69 0.31              4"},{"path":[]},{"path":"/index.html","id":"all-coefficients","dir":"","previous_headings":"Usage > Coefficients","what":"All coefficients","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"bolasso also supports moving beyond variable selection understanding bootstrapped variable coefficients. can extract tidy tibble variable column, row represents bootstrap fold, values corresponding estimated coefficients. bolasso also allows us plot bootstrap distribution variable coefficients. Suppose want quickly inspect distribution variables. can achieve simply plotting model.  Now, suppose example particularly interested coefficient distributions triceps, pressure, glucose variables. can plot distributions just variables:  Note: 30 variables included model, plot 30 variables largest absolute mean coefficients.","code":"tidy(model, select = \"lambda.min\") #> # A tibble: 100 √ó 10 #>    id     Intercept pregnant glucose pressure triceps   insulin   mass pedigree #>    <chr>      <dbl>    <dbl>   <dbl>    <dbl>   <dbl>     <dbl>  <dbl>    <dbl> #>  1 boot1      -8.80   0.117   0.0384 -0.00768 0.00459 -0.00313  0.0800  1.08    #>  2 boot2      -7.26   0.112   0.0331 -0.00633 0.00873 -0.00246  0.0675  0.00375 #>  3 boot3      -7.17   0.143   0.0257 -0.0221  0.00815 -0.00262  0.112   0.717   #>  4 boot4      -7.08   0.130   0.0240 -0.0133  0.00517  0        0.0789  0.716   #>  5 boot5      -6.14   0.0473  0.0215 -0.00661 0.00237 -0.00173  0.0793  0.305   #>  6 boot6      -7.92   0.0634  0.0247  0       0       -0.000142 0.0666  1.10    #>  7 boot7      -6.88   0.101   0.0326 -0.0224  0.0129  -0.00100  0.0656  1.16    #>  8 boot8      -7.93   0.0761  0.0258 -0.0141  0.0102  -0.00103  0.0937  0.471   #>  9 boot9      -6.37   0.202   0.0238 -0.00875 0.0106  -0.000555 0.0613  0       #> 10 boot10     -8.39   0.0926  0.0337 -0.0104  0.00500 -0.000949 0.0779  0.793   #> # ‚Ñπ 90 more rows #> # ‚Ñπ 1 more variable: age <dbl> plot(model, select = \"lambda.min\") plot(model, covariates = c(glucose, pressure, triceps))"},{"path":"/index.html","id":"selected-variable-coefficients","dir":"","previous_headings":"Usage > Coefficients","what":"Selected variable coefficients","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"want plot coefficient distributions selected variables, can use plot_selected_variables give us pretty much thing plot.  Just like plot can also focus subset selected variables.","code":"plot_selected_variables(   model,   threshold = 0.95,   method = \"vip\",   select = \"lambda.min\" ) plot_selected_variables(   model,   covariates = c(pregnant, mass),   threshold = 0.95,   method = \"vip\",   select = \"lambda.min\" )"},{"path":"/index.html","id":"predictions","dir":"","previous_headings":"Usage","what":"Predictions","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"Finally, can make predictions using bolasso model new data. example, following code shows generate predicted probabilites test data. Note outputs (n x p) matrix predictions n number rows test set, p number bootstraps, column represents predictions one bootstrapped models. combine single prediction per observation, take average observation across models:","code":"as_tibble(predict(model, test, select = \"lambda.min\", type = \"response\")) #> # A tibble: 230 √ó 100 #>    boot1 boot2 boot3 boot4 boot5 boot6 boot7 boot8 boot9 boot10 boot11 boot12 #>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl> #>  1 0.784 0.732 0.747 0.687 0.669 0.684 0.783 0.717 0.675  0.763  0.643  0.768 #>  2 0.239 0.295 0.260 0.212 0.353 0.232 0.156 0.199 0.249  0.215  0.268  0.161 #>  3 0.644 0.600 0.482 0.595 0.523 0.646 0.700 0.566 0.555  0.696  0.581  0.661 #>  4 0.321 0.316 0.633 0.431 0.367 0.203 0.558 0.349 0.407  0.331  0.369  0.376 #>  5 0.239 0.259 0.283 0.253 0.335 0.262 0.308 0.265 0.215  0.264  0.242  0.285 #>  6 0.370 0.362 0.389 0.410 0.413 0.419 0.441 0.371 0.373  0.407  0.357  0.367 #>  7 0.958 0.931 0.903 0.858 0.865 0.873 0.893 0.860 0.861  0.931  0.874  0.862 #>  8 0.355 0.445 0.385 0.320 0.334 0.234 0.338 0.257 0.514  0.294  0.352  0.272 #>  9 0.427 0.517 0.508 0.505 0.426 0.378 0.480 0.426 0.644  0.460  0.481  0.393 #> 10 0.465 0.446 0.536 0.500 0.532 0.541 0.496 0.564 0.435  0.526  0.432  0.567 #> # ‚Ñπ 220 more rows #> # ‚Ñπ 88 more variables: boot13 <dbl>, boot14 <dbl>, boot15 <dbl>, boot16 <dbl>, #> #   boot17 <dbl>, boot18 <dbl>, boot19 <dbl>, boot20 <dbl>, boot21 <dbl>, #> #   boot22 <dbl>, boot23 <dbl>, boot24 <dbl>, boot25 <dbl>, boot26 <dbl>, #> #   boot27 <dbl>, boot28 <dbl>, boot29 <dbl>, boot30 <dbl>, boot31 <dbl>, #> #   boot32 <dbl>, boot33 <dbl>, boot34 <dbl>, boot35 <dbl>, boot36 <dbl>, #> #   boot37 <dbl>, boot38 <dbl>, boot39 <dbl>, boot40 <dbl>, boot41 <dbl>, ‚Ä¶ tibble(   predictions = rowMeans(     predict(model, test, select = \"lambda.min\", type = \"response\")   ) ) #> # A tibble: 230 √ó 1 #>    predictions #>          <dbl> #>  1       0.704 #>  2       0.254 #>  3       0.637 #>  4       0.372 #>  5       0.268 #>  6       0.395 #>  7       0.906 #>  8       0.328 #>  9       0.465 #> 10       0.470 #> # ‚Ñπ 220 more rows"},{"path":"/index.html","id":"fast-estimation-Ô∏è","dir":"","previous_headings":"Usage","what":"Fast estimation üèéÔ∏èüí®","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"bootstrapped model, bolasso uses cross-validation find optimal regularization parameter lambda. glmnet, default number cross-validation folds 10. can quickly become computationally expensive slow, especially using many bootstrap replicates. example, 1,000 bootstrap replicates, results estimating models 10,000 cross-validation sets. address , can activate fast = TRUE argument bolasso. Instead using cross-validation find optimal lambda bootstrap model, fast bolasso runs single cross-validated regression full dataset identify optimal lambda. bootstrapped model uses lambda regularization parameter. following comparison shows computation time standard bolasso vs fast bolasso across increasing bootstrap replicates. plot displays number seconds algorithm takes complete.  Fast bolasso clearly achieves pretty massive speedups standard version! difference speed accentuated estimating larger datasets.","code":"# Compare standard vs. fast bolasso across different bootstrap values times <- lapply(   c(10, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1e3),   \\(x) {     time_standard <- system.time({       bolasso(         diabetes ~ .,         data = train,         n.boot = x,         progress = FALSE,         family = \"binomial\"       )     })     time_fast <- system.time({       bolasso(         diabetes ~ .,         data = train,         n.boot = x,         progress = FALSE,         family = \"binomial\",         fast = TRUE       )     })     return(       tibble::tibble(\"regular\" = time_standard[[3]], \"fast\" = time_fast[[3]])     )   } )  # Make a data.frame out of the times times_df <- do.call(rbind, times) |>   transform(     id = 1:11,     n_bootstrap = c(10, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1e3)   ) |>   reshape(     varying = c(\"regular\", \"fast\"),     v.names = \"time\",     times = c(\"regular\", \"fast\"),     timevar = \"algorithm\",     idvar = c(\"id\", \"n_bootstrap\"),     direction = \"long\"   )  # Plot it! ggplot(times_df, aes(x = n_bootstrap, y = time, color = factor(algorithm))) +   geom_point() +   geom_line() +   labs(x = \"N Bootstraps\", y = \"Time (seconds)\") +   scale_y_continuous(breaks = seq(0, 60, 10)) +   theme_minimal() +   theme(legend.title = element_blank())"},{"path":"/index.html","id":"what-do-we-lose-with-standard-vs-fast","dir":"","previous_headings":"Usage > Fast estimation üèéÔ∏èüí®","what":"What do we lose with standard vs.¬†fast?","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"‚Äôs never free lunch, clear tradeoffs standard fast versions bolasso, following shows difference predictive accuracy hold-test set. ‚Äôs important note fast bolasso thought rough--ready algorithm better quick iteration might worse empirical performance standard algorithm.","code":"model_standard <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\" ) model_fast <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\",   fast = TRUE )  model_standard_preds <- ifelse(   rowMeans(predict(model_standard, test, type = \"response\")) >= 0.5,   yes = 1,   no = 0 ) model_fast_preds <- ifelse(   rowMeans(predict(model_fast, test, type = \"response\")) >= 0.5,   yes = 1,   no = 0 ) truth <- as.integer(test$diabetes) - 1 #> Standard Bolasso accuracy: 80.87 % #>  Fast Bolasso accuracy: 80.43 %"},{"path":"/index.html","id":"parallelizing-bolasso","dir":"","previous_headings":"Usage > Fast estimation üèéÔ∏èüí®","what":"Parallelizing bolasso","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"can also fit bolasso bootstrap models parallel via future package. future package supports wide variety parallelization, local multi-core remote compute clusters. Parallelizing bolasso simple initializing parallel method prior executing bolasso function. example, following setup execute bolasso parallel R sessions.","code":"future::plan(\"multisession\") time_parallel <- system.time({   bolasso(     diabetes ~ .,     data = train,     n.boot = 1000,     progress = FALSE,     family = \"binomial\"   ) }) future::plan(\"sequential\")  time_sequential <- system.time({   bolasso(     diabetes ~ .,     data = train,     n.boot = 1000,     progress = FALSE,     family = \"binomial\"   ) }) #> Parallel bolasso time (seconds): 10.699  #> Sequential bolasso time (seconds): 41.497"},{"path":"/index.html","id":"beyond-the-lasso","dir":"","previous_headings":"Usage","what":"Beyond the Lasso","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"bolasso also allows us fit penalized regression models beyond Lasso. example, suppose want fit bootstrap-enhanced elasticnet model mixing parameter 0.5 (even mix Ridge Lasso regularization terms). can simply pass underlying glmnet::glmnet argument alpha = 0.5 bolasso. following code compares selected variables Lasso elasticnet models.","code":"lasso <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\" )  elnet <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\",   alpha = 0.5 ) #> Lasso selected variables: pregnant glucose mass age  #> Elnet selected variables: pregnant glucose mass pedigree age"},{"path":"/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"[1]Abram, Samantha V et al.¬†‚ÄúBootstrap Enhanced Penalized Regression Variable Selection Neuroimaging Data.‚Äù Frontiers neuroscience vol.¬†10 344. 28 Jul.¬†2016, doi:10.3389/fnins.2016.00344 [2]Bach, Francis. ‚ÄúBolasso: Model Consistent Lasso Estimation Bootstrap.‚Äù ArXiv:0804.1302 [Cs, Math, Stat], 2008. https://arxiv.org/abs/0804.1302. [3]Bunea, Florentina et al.¬†‚ÄúPenalized least squares regression methods applications neuroimaging.‚Äù NeuroImage vol.¬†55,4 (2011): 1519-27. doi:10.1016/j.neuroimage.2010.12.028","code":""},{"path":"/reference/bolasso.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootsrap-enhanced Lasso ‚Äî bolasso","title":"Bootsrap-enhanced Lasso ‚Äî bolasso","text":"function implements model-consistent Lasso estimation bootstrap. supports parallel processing way future package, allowing user flexibly specify many parallelization methods. method developed variable-selection algorithm, package also supports making ensemble predictions new data using bagged Lasso models.","code":""},{"path":"/reference/bolasso.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootsrap-enhanced Lasso ‚Äî bolasso","text":"","code":"bolasso(   formula,   data,   n.boot = 100,   progress = TRUE,   implement = c(\"glmnet\", \"gamlr\"),   x = NULL,   y = NULL,   fast = FALSE,   ... )"},{"path":"/reference/bolasso.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootsrap-enhanced Lasso ‚Äî bolasso","text":"formula optional object class formula (one can coerced class): symbolic description model fitted. Can omitted x y non-missing. data optional object class data.frame contains modeling variables referenced form. Can omitted x y non-missing. n.boot integer specifying number bootstrap replicates. progress boolean indicating whether display progress across bootstrap folds. implement character; either 'glmnet' 'gamlr', specifying Lasso implementation utilize. specific modeling details, see glmnet::cv.glmnet gamlr::cv.gamlr. x optional predictor matrix lieu form data. y optional response vector lieu form data. fast boolean. Whether fit \"fast\" bootstrap procedure. fast == TRUE, bolasso fit glmnet::cv.glmnet entire dataset. fit bootstrapped models value lambda (regularization parameter) minimized cross-validation loss full model. fast == FALSE (default), bolasso use cross-validation find optimal lambda bootstrap model. ... Additional parameters pass either glmnet::cv.glmnet gamlr::cv.gamlr.","code":""},{"path":"/reference/bolasso.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootsrap-enhanced Lasso ‚Äî bolasso","text":"object class bolasso. object list length n.boot cv.glmnet cv.gamlr objects.","code":""},{"path":[]},{"path":"/reference/bolasso.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootsrap-enhanced Lasso ‚Äî bolasso","text":"","code":"mtcars[, c(2, 10:11)] <- lapply(mtcars[, c(2, 10:11)], as.factor) idx <- sample(nrow(mtcars), 22) mtcars_train <- mtcars[idx, ] mtcars_test <- mtcars[-idx, ]  ## Formula Interface  # Train model set.seed(123) bolasso_form <- bolasso(   form = mpg ~ .,   data = mtcars_train,   n.boot = 20,   nfolds = 5 ) #> Loaded glmnet 4.1-8  # Retrieve a tidy tibble of bootstrap coefficients for each covariate tidy(bolasso_form) #> # A tibble: 20 √ó 19 #>    id    Intercept  cyl4   cyl6     cyl8     disp       hp    drat     wt   qsec #>    <chr>     <dbl> <dbl>  <dbl>    <dbl>    <dbl>    <dbl>   <dbl>  <dbl>  <dbl> #>  1 boot1     33.2  0     -1.49   0        0       -0.0379  0       -2.43   0     #>  2 boot2     31.8  2.48   0     -1.50e+0  0       -0.00705 0       -3.70   0     #>  3 boot3     22.0  5.55   0      0        0       -0.0134  0       -0.911  0     #>  4 boot4     27.0  0     -1.22   9.70e-1  0       -0.0840  1.08e+0  0      0     #>  5 boot5     22.7  0      0      0       -0.00680 -0.0365  1.65e+0 -0.654  0     #>  6 boot6     31.0  1.52   0      0        0       -0.0201  0       -2.96   0     #>  7 boot7     14.3  1.86   0     -1.26e+0  0       -0.00539 7.41e+0  0     -0.780 #>  8 boot8     17.7  1.93   0      0        0        0       9.43e-1 -2.24   0.393 #>  9 boot9     36.1  0.998 -0.109  0        0       -0.0295  0       -3.63   0     #> 10 boot‚Ä¶     28.3  3.42   0      0        0        0       0       -3.13   0     #> 11 boot‚Ä¶     22.0  4.41   0      0        0        0       2.82e+0 -0.617 -0.690 #> 12 boot‚Ä¶      7.85 0.894  0     -2.71e+0  0        0       3.54e+0  0      0     #> 13 boot‚Ä¶      9.33 2.58   0     -9.25e-1  0        0       0       -0.701  0.401 #> 14 boot‚Ä¶      8.65 0      0     -5.72e-1  0        0       2.59e+0  0      0     #> 15 boot‚Ä¶     23.0  2.40   0     -3.00e-4  0       -0.0355  0        0      0     #> 16 boot‚Ä¶     24.3  0.460  0     -3.01e-1 -0.0107   0       1.96e-4 -1.15   0     #> 17 boot‚Ä¶     22.2  2.68   0     -1.76e+0 -0.00510  0       0       -1.05   0     #> 18 boot‚Ä¶     33.7  1.08   0      0        0       -0.0256  0       -3.20   0     #> 19 boot‚Ä¶     30.8  1.84   0      0        0       -0.0244  0       -2.78   0     #> 20 boot‚Ä¶     25.9  0      0     -2.67e+0 -0.00332 -0.00989 4.77e-1 -1.69   0     #> # ‚Ñπ 9 more variables: vs <dbl>, am <dbl>, gear4 <dbl>, gear5 <dbl>, #> #   carb2 <dbl>, carb3 <dbl>, carb4 <dbl>, carb6 <dbl>, carb8 <dbl>  # Extract selected variables selected_variables(bolasso_form, threshold = 0.9, select = \"lambda.min\") #> # A tibble: 20 √ó 1 #>    id     #>    <chr>  #>  1 boot1  #>  2 boot2  #>  3 boot3  #>  4 boot4  #>  5 boot5  #>  6 boot6  #>  7 boot7  #>  8 boot8  #>  9 boot9  #> 10 boot10 #> 11 boot11 #> 12 boot12 #> 13 boot13 #> 14 boot14 #> 15 boot15 #> 16 boot16 #> 17 boot17 #> 18 boot18 #> 19 boot19 #> 20 boot20  # Bagged ensemble prediction on test data predict(bolasso_form,         new.data = mtcars_test,         select = \"lambda.min\") #>                     boot1    boot2    boot3     boot4    boot5    boot6 #> Mazda RX4        23.53203 21.31155 20.38801 22.290720 22.27351 21.94408 #> Datsun 710       26.39838 25.65987 30.73719 27.331865 23.36205 24.69222 #> Duster 360       15.27134 15.34670 13.64426  8.423965 14.22472 15.46800 #> Merc 240D        23.13465 22.65999 27.44668 21.980070 23.39864 21.78321 #> Merc 280         18.72157 18.82589 18.99172 17.249912 21.24348 18.30049 #> Honda Civic      29.66803 28.55722 31.92853 28.131520 27.31862 27.60294 #> Toyota Corolla   28.63992 27.65163 31.55401 30.084933 25.56220 26.69050 #> Camaro Z28       14.61451 14.34784 13.39836  8.986365 14.97222 14.66826 #> Pontiac Firebird 17.25657 14.82313 16.19174 12.794893 16.11565 16.05771 #> Maserati Bora    14.18150 14.71184 17.21216  8.396929 11.88185 14.61647 #>                     boot7    boot8    boot9   boot10   boot11   boot12   boot13 #> Mazda RX4        21.42965 18.82831 23.22819 20.14767 15.38615 21.52801 20.42563 #> Datsun 710       31.17257 25.62445 25.92730 24.50229 26.38631 26.26061 29.43843 #> Duster 360       13.31440 15.80368 15.89598 17.17782 15.19136 12.60124 10.22709 #> Merc 240D        23.64343 21.01089 23.67867 21.78253 24.44045 21.91810 26.32699 #> Merc 280         18.29764 17.98024 19.86190 17.58422 18.97526 17.93253 17.81826 #> Honda Civic      35.80988 25.13158 29.70004 26.70624 29.92394 30.08307 32.93965 #> Toyota Corolla   33.05723 27.56742 28.51666 26.01848 26.83720 27.57016 30.29603 #> Camaro Z28       17.50096 15.51962 14.91479 16.33376 16.78562 14.44168  9.86533 #> Pontiac Firebird 17.97528 15.62626 16.96378 16.31812 16.54070 16.04707 15.59535 #> Maserati Bora    20.20025 17.60688 13.24071 17.30561 19.69561 21.45137 17.86446 #>                    boot14   boot15   boot16   boot17   boot18   boot19   boot20 #> Mazda RX4        20.96366 23.00697 19.63938 20.72184 22.53705 21.92048 21.68905 #> Datsun 710       29.04419 26.01095 21.00265 25.77933 25.60174 25.00468 22.52004 #> Duster 360       12.14012 14.26750 16.01328 14.81375 15.41257 14.91257 15.08037 #> Merc 240D        22.16729 23.64211 19.49836 23.43581 22.98283 22.26822 21.15043 #> Merc 280         18.50003 19.07564 18.52614 19.48435 18.95140 18.24974 20.15770 #> Honda Civic      31.84528 27.46691 22.16310 27.58397 28.90394 27.96428 24.74005 #> Toyota Corolla   30.00382 27.00526 21.95821 26.47687 27.86820 27.03570 23.91624 #> Camaro Z28       13.48879 14.26750 15.80876 14.58134 14.54991 14.16212 14.90464 #> Pontiac Firebird 16.06674 16.75329 15.26705 15.22047 16.91750 15.85567 15.11960 #> Maserati Bora    24.75042 14.54118 16.73050 17.24715 14.33267 13.79177 14.54958  ## Alternate Matrix Interface  # Train model set.seed(123) bolasso_mat <- bolasso(   x = model.matrix(mpg ~ . - 1, mtcars_train),   y = mtcars_train[, 1],   data = mtcars_train,   n.boot = 20,   nfolds = 5 )  # Bagged ensemble prediction on test data predict(bolasso_mat,         new.data = model.matrix(mpg ~ . - 1, mtcars_test),         select = \"lambda.min\") #>                     boot1    boot2    boot3     boot4    boot5    boot6 #> Mazda RX4        23.53203 21.31155 20.38801 22.290720 22.27351 21.94408 #> Datsun 710       26.39838 25.65987 30.73719 27.331865 23.36205 24.69222 #> Duster 360       15.27134 15.34670 13.64426  8.423965 14.22472 15.46800 #> Merc 240D        23.13465 22.65999 27.44668 21.980070 23.39864 21.78321 #> Merc 280         18.72157 18.82589 18.99172 17.249912 21.24348 18.30049 #> Honda Civic      29.66803 28.55722 31.92853 28.131520 27.31862 27.60294 #> Toyota Corolla   28.63992 27.65163 31.55401 30.084933 25.56220 26.69050 #> Camaro Z28       14.61451 14.34784 13.39836  8.986365 14.97222 14.66826 #> Pontiac Firebird 17.25657 14.82313 16.19174 12.794893 16.11565 16.05771 #> Maserati Bora    14.18150 14.71184 17.21216  8.396929 11.88185 14.61647 #>                     boot7    boot8    boot9   boot10   boot11   boot12   boot13 #> Mazda RX4        21.42965 18.82831 23.22819 20.14767 15.38615 21.52801 20.42563 #> Datsun 710       31.17257 25.62445 25.92730 24.50229 26.38631 26.26061 29.43843 #> Duster 360       13.31440 15.80368 15.89598 17.17782 15.19136 12.60124 10.22709 #> Merc 240D        23.64343 21.01089 23.67867 21.78253 24.44045 21.91810 26.32699 #> Merc 280         18.29764 17.98024 19.86190 17.58422 18.97526 17.93253 17.81826 #> Honda Civic      35.80988 25.13158 29.70004 26.70624 29.92394 30.08307 32.93965 #> Toyota Corolla   33.05723 27.56742 28.51666 26.01848 26.83720 27.57016 30.29603 #> Camaro Z28       17.50096 15.51962 14.91479 16.33376 16.78562 14.44168  9.86533 #> Pontiac Firebird 17.97528 15.62626 16.96378 16.31812 16.54070 16.04707 15.59535 #> Maserati Bora    20.20025 17.60688 13.24071 17.30561 19.69561 21.45137 17.86446 #>                    boot14   boot15   boot16   boot17   boot18   boot19   boot20 #> Mazda RX4        20.96366 23.00697 19.63938 20.72184 22.53705 21.92048 21.68905 #> Datsun 710       29.04419 26.01095 21.00265 25.77933 25.60174 25.00468 22.52004 #> Duster 360       12.14012 14.26750 16.01328 14.81375 15.41257 14.91257 15.08037 #> Merc 240D        22.16729 23.64211 19.49836 23.43581 22.98283 22.26822 21.15043 #> Merc 280         18.50003 19.07564 18.52614 19.48435 18.95140 18.24974 20.15770 #> Honda Civic      31.84528 27.46691 22.16310 27.58397 28.90394 27.96428 24.74005 #> Toyota Corolla   30.00382 27.00526 21.95821 26.47687 27.86820 27.03570 23.91624 #> Camaro Z28       13.48879 14.26750 15.80876 14.58134 14.54991 14.16212 14.90464 #> Pontiac Firebird 16.06674 16.75329 15.26705 15.22047 16.91750 15.85567 15.11960 #> Maserati Bora    24.75042 14.54118 16.73050 17.24715 14.33267 13.79177 14.54958"},{"path":"/reference/plot.bolasso.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a bolasso object ‚Äî plot.bolasso","title":"Plot a bolasso object ‚Äî plot.bolasso","text":"method plots coefficient distributions covariates included bolasso model. 30 covariates included full model, plot 30 covariates largest absolute mean coefficient. user can also plot coefficient distributions specified subset covariates.","code":""},{"path":"/reference/plot.bolasso.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a bolasso object ‚Äî plot.bolasso","text":"","code":"# S3 method for class 'bolasso' plot(x, covariates = NULL, ...)"},{"path":"/reference/plot.bolasso.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a bolasso object ‚Äî plot.bolasso","text":"x object class bolasso bolasso_fast. covariates subset covariates plot. vector covariate names either strings bare. E.g. covariates = c(\"var_1\", \"var_2\") covariates = c(var_1, var_2). argument optional NULL default. case plot 30 covariates largest absolute mean coefficients. ... Additional arguments pass directly coef objects class bolasso bolasso_fast.","code":""},{"path":"/reference/plot_selected_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot selected variables from a bolasso object. ‚Äî plot_selected_variables","title":"Plot selected variables from a bolasso object. ‚Äî plot_selected_variables","text":"method plots coefficient distributions selected covariates bolasso model. 30 selected covariates, plot 30 selected covariates largest absolute mean coefficient. user can also plot coefficient distributions specified subset selected covariates.","code":""},{"path":"/reference/plot_selected_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot selected variables from a bolasso object. ‚Äî plot_selected_variables","text":"","code":"plot_selected_variables(   x,   covariates = NULL,   threshold = 0.95,   method = c(\"vip\", \"qnt\"),   ... )"},{"path":"/reference/plot_selected_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot selected variables from a bolasso object. ‚Äî plot_selected_variables","text":"x object class bolasso bolasso_fast. covariates subset selected covariates plot. vector covariate names either strings bare. E.g. covariates = c(\"var_1\", \"var_2\") covariates = c(var_1, var_2). argument optional NULL default. case plot 30 covariates largest absolute mean coefficients. threshold numeric 0 1, specifying variable selection threshold use. method variable selection method use. two valid options c(\"vip\", \"qnt\"). default \"vip\" method described original Bach (2008) complementary Bunea et al. (2011) works. \"qnt\" method method proposed Abram et al. (2016). ... Additional arguments pass coef objects class bolasso bolass_fast.","code":""},{"path":"/reference/plot_selection_thresholds.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot each covariate's smallest variable selection threshold ‚Äî plot_selection_thresholds","title":"Plot each covariate's smallest variable selection threshold ‚Äî plot_selection_thresholds","text":"Plot results selection_thresholds function.","code":""},{"path":"/reference/plot_selection_thresholds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot each covariate's smallest variable selection threshold ‚Äî plot_selection_thresholds","text":"","code":"plot_selection_thresholds(object = NULL, data = NULL, ...)"},{"path":"/reference/plot_selection_thresholds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot each covariate's smallest variable selection threshold ‚Äî plot_selection_thresholds","text":"object object class bolasso bolasso_fast. argument optional directly pass data via data argument. E.g. data = selection_thresholds(object). data dataframe containing selection thresholds. E.g. obtained via selection_thresholds(object). argument optional directly pass bolasso bolasso_fast object via object argument. ... Additional arguments pass directly selection_thresholds.","code":""},{"path":"/reference/plot_selection_thresholds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot each covariate's smallest variable selection threshold ‚Äî plot_selection_thresholds","text":"ggplot object","code":""},{"path":[]},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages ‚Äî reexports","title":"Objects exported from other packages ‚Äî reexports","text":"objects imported packages. Follow links see documentation. generics tidy","code":""},{"path":"/reference/selected_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Bolasso-selected Variables ‚Äî selected_variables","title":"Bolasso-selected Variables ‚Äî selected_variables","text":"Identifies covariates selected Bolasso algorithm user-defined threshold. two variable selection criterion choose ; Variable Inclusion Probability (\"vip\") introduced original Bolasso paper (Bach, 2008) developed Bunea et al. (2011), Quantile (\"qnt\") approach proposed Abram et al. (2016). desired threshold value 1 - alpha, alpha (typically small) significance level.","code":""},{"path":"/reference/selected_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bolasso-selected Variables ‚Äî selected_variables","text":"","code":"selected_variables(   object,   threshold = 0.95,   method = c(\"vip\", \"qnt\"),   var_names_only = FALSE,   ... )"},{"path":"/reference/selected_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bolasso-selected Variables ‚Äî selected_variables","text":"object object class bolasso. threshold numeric 0 1, specifying variable selection threshold use. method variable selection method use. two valid options c(\"vip\", \"qnt\"). default \"vip\" method described original Bach (2008) complementary Bunea et al. (2011) works. \"qnt\" method method proposed Abram et al. (2016). var_names_only boolean value. var_names_only = FALSE (default value) function return tibble::tibble selected covariates corresponding coefficients across bootstrap replicates. var_names_only == TRUE, return vector containing selected covariate names. ... Additional arguments pass coef objects class bolasso bolass_fast.","code":""},{"path":"/reference/selected_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bolasso-selected Variables ‚Äî selected_variables","text":"tibble selected variable respective coefficient bootstrap replicate vector names selected variables.","code":""},{"path":"/reference/selected_variables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bolasso-selected Variables ‚Äî selected_variables","text":"function returns either tibble::tibble selected covariates corresponding coefficients across bootstrap replicates, vector selected covariate names.","code":""},{"path":[]},{"path":"/reference/selection_thresholds.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate each covariate's smallest variable selection threshold ‚Äî selection_thresholds","title":"Calculate each covariate's smallest variable selection threshold ‚Äî selection_thresholds","text":"two methods variable selection covariates. first Variable Inclusion Probability (VIP) introduced Bach (2008) generalized Bunea et al (2011). second Quantile confidence interval (QNT) proposed Abram et al (2016). given level significance alpha, method selects covariates given threshold = 1 - alpha. higher threshold (lower alpha), stringent variable selection criterion.","code":""},{"path":"/reference/selection_thresholds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate each covariate's smallest variable selection threshold ‚Äî selection_thresholds","text":"","code":"selection_thresholds(object, grid = seq(0, 1, by = 0.01), ...)"},{"path":"/reference/selection_thresholds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate each covariate's smallest variable selection threshold ‚Äî selection_thresholds","text":"object object class bolasso bolasso_fast. grid vector numbers 0 1 (inclusive) specifying grid threshold values calculate variable inclusion criterion . Defaults seq(0, 1, = 0.01). ... Additional parameters pass coef objects class bolasso bolasso_fast.","code":""},{"path":"/reference/selection_thresholds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate each covariate's smallest variable selection threshold ‚Äî selection_thresholds","text":"tibble dimension (2*p)x5 p number covariates.","code":""},{"path":"/reference/selection_thresholds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate each covariate's smallest variable selection threshold ‚Äî selection_thresholds","text":"function returns tibble , covariate, returns largest threshold (equivalently smallest alpha) selected VIP QNT methods. Consequently number rows returned tibble 2*p p number covariates included model.","code":""},{"path":"/reference/tidy.bolasso.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a bolasso object ‚Äî tidy.bolasso","title":"Tidy a bolasso object ‚Äî tidy.bolasso","text":"Tidy bolasso object","code":""},{"path":"/reference/tidy.bolasso.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a bolasso object ‚Äî tidy.bolasso","text":"","code":"# S3 method for class 'bolasso' tidy(x, select = c(\"lambda.min\", \"lambda.1se\", \"min\", \"1se\"), ...)"},{"path":"/reference/tidy.bolasso.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a bolasso object ‚Äî tidy.bolasso","text":"x bolasso object. select One \"min\", \"1se\", \"lambda.min\", \"lambda.1se\". \"min\" \"lambda.min\" equivalent lambda value minimizes cv MSE. Similarly \"1se\" \"lambda.1se\" equivalent refer lambda achieves regularization within 1se minimal cv MSE. ... Additional arguments pass directly coef.bolasso.","code":""},{"path":"/reference/tidy.bolasso.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy a bolasso object ‚Äî tidy.bolasso","text":"tidy tibble::tibble() summarizing bootstrap-level coefficients covariate.","code":""},{"path":"/reference/transactions.html","id":null,"dir":"Reference","previous_headings":"","what":"Customer transaction data ‚Äî transactions","title":"Customer transaction data ‚Äî transactions","text":"Predict whether customers make specific transaction based rich set user features.","code":""},{"path":"/reference/transactions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Customer transaction data ‚Äî transactions","text":"","code":"transactions"},{"path":"/reference/transactions.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Customer transaction data ‚Äî transactions","text":"Dataframe columns target integer indicating whether customer engaged transaction. var_i 200 numeric features various customer characteristics.","code":""},{"path":"/news/index.html","id":"bolasso-030","dir":"Changelog","previous_headings":"","what":"bolasso 0.3.0","title":"bolasso 0.3.0","text":"CRAN release: 2024-12-08","code":""},{"path":"/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"bolasso 0.3.0","text":"bolasso() gains fast argument optimizes computation using single cross-validated regression entire dataset determine optimal regularization parameter (lambda). approach bypasses need cross-validation within bootstrap replicate, drastically reducing computation time, especially beneficial large datasets using high number bootstrap replicates. selected_vars() now shorthand selected_variables(). selected_variables()/selected_vars() supports two variable selection algorithms via method argument: Variable Inclusion Probability (VIP) method Quantile (QNT) method. VIP method selects variables appear high percentage bootstrap models, QNT method selects variables based bootstrap confidence intervals. Set method = \"vip\" method = \"qnt\", respectively. tidy() extracts tidy tibble summarizing bootstrap-level coefficients covariate. method provides clean organized way inspect model coefficients. plot_selection_thresholds() provides visual representation selection thresholds variable. visualization helps users understand stability robustness variable selection across different thresholds methods.","code":"# Fast mode reduces computation time by using a single cross-validated lambda model_fast <- bolasso( diabetes ~ ., data = train, n.boot = 1000, progress = FALSE, family = \"binomial\", fast = TRUE ) # Select variables using the VIP method with a 95% threshold selected_vars_vip <- selected_variables(model, threshold = 0.95, method = \"vip\")  # Select variables using the QNT method selected_vars_qnt <- selected_variables(model, threshold = 0.95, method = \"qnt\") # Extract a tidy tibble of coefficients tidy_coefs <- tidy(model, select = \"lambda.min\") # Visualize selection thresholds for variables plot_selection_thresholds(model, select = \"lambda.min\")"},{"path":"/news/index.html","id":"improvements-0-3-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"bolasso 0.3.0","text":"plot_selected_variables() visualizes coefficient distributions selected variables. function provides focused view relevant variables model. plot visualizes coefficient distributions model covariates.","code":"# Plot coefficient distributions for selected variables plot_selected_variables( model, threshold = 0.95, method = \"vip\", select = \"lambda.min\" ) # Plot coefficient distributions for selected variables plot(model, select = \"lambda.min\")"},{"path":"/news/index.html","id":"bolasso-020","dir":"Changelog","previous_headings":"","what":"bolasso 0.2.0","title":"bolasso 0.2.0","text":"CRAN release: 2022-05-09 Added NEWS.md file track changes package. bolasso() argument form renamed formula reflect common naming conventions R statistical modeling packages. predict() coef() methods now implemented using future.apply::future_lapply allowing computing predictions extracting coefficients parallel. may result slightly worse performance (due memory overhead) model/prediction data small significantly faster e.g.¬†generating predictions large data-set. Solved issue bolasso() argument formula. user-supplied value formula handled via deparse() default width.cutoff value 60. causing issues formulas splitting multi-element character vectors. now set maximum value 500L correctly parse lengths formulas. predict() now forces evaluation formula argument bolasso() call. resolves issue , user passes formula via variable, predict() pass variable name underlying prediction function opposed actual formula.","code":""}]
