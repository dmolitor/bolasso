[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 bolasso authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Molitor. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Molitor D (2025). bolasso: Model Consistent Lasso Estimation Bootstrap. R package version 0.4.0, https://www.dmolitor.com/bolasso/.","code":"@Manual{,   title = {bolasso: Model Consistent Lasso Estimation Through the Bootstrap},   author = {Daniel Molitor},   year = {2025},   note = {R package version 0.4.0},   url = {https://www.dmolitor.com/bolasso/}, }"},{"path":"/index.html","id":"bolasso-","dir":"","previous_headings":"","what":"Model Consistent Lasso Estimation Through the Bootstrap","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"goal bolasso implement bootstrap-enhanced Lasso (generally, penalized regression) estimation, proposed originally Bach (2008) extended Bunea et al. (2011) Abram et al. (2016). methods focus primarily variable selection propose two similar, slightly different, variable selection algorithms; variable inclusion probability (VIP) algorithm (Bach; Bunea et al.), bootstrap distribution quantile (QNT) algorithm (Abram et al.). Beyond implementing variable selection methods, bolasso also provides utilities making bagged predictions, examining coefficient distributions, plotting.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"Install bolasso CRAN: install development version GitHub :","code":"install.packages(\"bolasso\") # install.packages(\"pak\") pak::pkg_install(\"dmolitor/bolasso@dev\")"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"illustrate usage bolasso, ’ll use Pima Indians Diabetes dataset determine factors important predictors testing positive diabetes. full description input variables, see link .","code":""},{"path":"/index.html","id":"load-requisite-packages-and-data","dir":"","previous_headings":"Usage","what":"Load requisite packages and data","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"First, let’s create train/test split data, run 100-fold bootstrapped Lasso glmnet.","code":"library(bolasso) library(ggplot2) library(tibble)  data(PimaIndiansDiabetes, package = \"mlbench\")  # Quick overview of the dataset str(PimaIndiansDiabetes) #> 'data.frame':    768 obs. of  9 variables: #>  $ pregnant: num  6 1 8 1 0 5 3 10 2 8 ... #>  $ glucose : num  148 85 183 89 137 116 78 115 197 125 ... #>  $ pressure: num  72 66 64 66 40 74 50 0 70 96 ... #>  $ triceps : num  35 29 0 23 35 0 32 0 45 0 ... #>  $ insulin : num  0 0 0 94 168 0 88 0 543 0 ... #>  $ mass    : num  33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 0 ... #>  $ pedigree: num  0.627 0.351 0.672 0.167 2.288 ... #>  $ age     : num  50 31 32 21 33 30 26 29 53 54 ... #>  $ diabetes: Factor w/ 2 levels \"neg\",\"pos\": 2 1 2 1 2 1 2 1 2 2 ... train_idx <- sample(1:nrow(PimaIndiansDiabetes), round(0.7*nrow(PimaIndiansDiabetes))) train <- PimaIndiansDiabetes[train_idx, ] test <- PimaIndiansDiabetes[-train_idx, ]  model <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\" ) #> Loaded glmnet 4.1-8"},{"path":"/index.html","id":"variable-selection","dir":"","previous_headings":"Usage","what":"Variable selection","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"Next, using threshold 0.95 can extract selected variables using VIP method, extracts variables selected (non-zero coefficients) >= 95% bootstrapped models. ’ll use regularization parameter lambda.min minimizes cross-validation error. Note returned tibble selected variables columns coefficients bootstrapped models rows. want simply return variable names, can add var_names_only argument: can compare selected variables using VIP method QNT method, selects variables 95% bootstrap confidence interval contain 0: Note number selected variables QNT always <= VIP. default method bolasso method = \"vip\".","code":"selected_variables(model, threshold = 0.95, method = \"vip\", select = \"lambda.min\") #> # A tibble: 100 × 5 #>    id     pregnant glucose   mass    age #>    <chr>     <dbl>   <dbl>  <dbl>  <dbl> #>  1 boot1    0.117   0.0384 0.0800 0.0145 #>  2 boot2    0.112   0.0331 0.0675 0.0115 #>  3 boot3    0.143   0.0257 0.112  0.0135 #>  4 boot4    0.130   0.0240 0.0789 0.0240 #>  5 boot5    0.0473  0.0215 0.0793 0.0183 #>  6 boot6    0.0634  0.0247 0.0666 0.0346 #>  7 boot7    0.101   0.0326 0.0656 0.0194 #>  8 boot8    0.0761  0.0258 0.0937 0.0359 #>  9 boot9    0.202   0.0238 0.0613 0.0113 #> 10 boot10   0.0926  0.0337 0.0779 0.0293 #> # ℹ 90 more rows selected_variables(model, 0.95, \"vip\", var_names_only = TRUE) #> [1] \"pregnant\" \"glucose\"  \"mass\"     \"age\" selected_variables(model, 0.95, \"qnt\", var_names_only = TRUE) #> [1] \"pregnant\" \"glucose\"  \"mass\""},{"path":"/index.html","id":"variable-selection-thresholds","dir":"","previous_headings":"Usage > Variable selection","what":"Variable selection thresholds","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"may , instead selecting variables given threshold method, want see largest threshold variable selected VIP QNT methods. can quickly visualize plot_selection_thresholds function.  can also get thresholds tibble:","code":"plot_selection_thresholds(model, select = \"lambda.min\") selection_thresholds(model, select = \"lambda.min\") #> # A tibble: 16 × 5 #>    covariate method threshold  alpha covariate_id #>    <chr>     <chr>      <dbl>  <dbl>        <int> #>  1 age       QNT         0.93 0.0700            8 #>  2 glucose   QNT         1    0                 2 #>  3 insulin   QNT         0.39 0.61              5 #>  4 mass      QNT         1    0                 6 #>  5 pedigree  QNT         0.77 0.23              7 #>  6 pregnant  QNT         1    0                 1 #>  7 pressure  QNT         0.65 0.35              3 #>  8 triceps   QNT         0    1                 4 #>  9 age       VIP         0.97 0.0300            8 #> 10 glucose   VIP         1    0                 2 #> 11 insulin   VIP         0.78 0.22              5 #> 12 mass      VIP         1    0                 6 #> 13 pedigree  VIP         0.9  0.1               7 #> 14 pregnant  VIP         1    0                 1 #> 15 pressure  VIP         0.84 0.16              3 #> 16 triceps   VIP         0.69 0.31              4"},{"path":[]},{"path":"/index.html","id":"all-coefficients","dir":"","previous_headings":"Usage > Coefficients","what":"All coefficients","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"bolasso also supports moving beyond variable selection understanding bootstrapped variable coefficients. can extract tidy tibble variable column, row represents bootstrap fold, values corresponding estimated coefficients. bolasso also allows us plot bootstrap distribution variable coefficients. Suppose want quickly inspect distribution variables. can achieve simply plotting model.  Now, suppose example particularly interested coefficient distributions triceps, pressure, glucose variables. can plot distributions just variables:  Note: 30 variables included model, plot 30 variables largest absolute mean coefficients.","code":"tidy(model, select = \"lambda.min\") #> # A tibble: 100 × 10 #>    id     Intercept pregnant glucose pressure triceps   insulin   mass pedigree #>    <chr>      <dbl>    <dbl>   <dbl>    <dbl>   <dbl>     <dbl>  <dbl>    <dbl> #>  1 boot1      -8.80   0.117   0.0384 -0.00768 0.00459 -0.00313  0.0800  1.08    #>  2 boot2      -7.26   0.112   0.0331 -0.00633 0.00873 -0.00246  0.0675  0.00375 #>  3 boot3      -7.17   0.143   0.0257 -0.0221  0.00815 -0.00262  0.112   0.717   #>  4 boot4      -7.08   0.130   0.0240 -0.0133  0.00517  0        0.0789  0.716   #>  5 boot5      -6.14   0.0473  0.0215 -0.00661 0.00237 -0.00173  0.0793  0.305   #>  6 boot6      -7.92   0.0634  0.0247  0       0       -0.000142 0.0666  1.10    #>  7 boot7      -6.88   0.101   0.0326 -0.0224  0.0129  -0.00100  0.0656  1.16    #>  8 boot8      -7.93   0.0761  0.0258 -0.0141  0.0102  -0.00103  0.0937  0.471   #>  9 boot9      -6.37   0.202   0.0238 -0.00875 0.0106  -0.000555 0.0613  0       #> 10 boot10     -8.39   0.0926  0.0337 -0.0104  0.00500 -0.000949 0.0779  0.793   #> # ℹ 90 more rows #> # ℹ 1 more variable: age <dbl> plot(model, select = \"lambda.min\") plot(model, covariates = c(glucose, pressure, triceps))"},{"path":"/index.html","id":"selected-variable-coefficients","dir":"","previous_headings":"Usage > Coefficients","what":"Selected variable coefficients","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"want plot coefficient distributions selected variables, can use plot_selected_variables give us pretty much thing plot.  Just like plot can also focus subset selected variables.","code":"plot_selected_variables(   model,   threshold = 0.95,   method = \"vip\",   select = \"lambda.min\" ) plot_selected_variables(   model,   covariates = c(pregnant, mass),   threshold = 0.95,   method = \"vip\",   select = \"lambda.min\" )"},{"path":"/index.html","id":"predictions","dir":"","previous_headings":"Usage","what":"Predictions","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"Finally, can make predictions using bolasso model new data. example, following code shows generate predicted probabilites test data. Note outputs (n x p) matrix predictions n number rows test set, p number bootstraps, column represents predictions one bootstrapped models. combine single prediction per observation, take average observation across models:","code":"as_tibble(predict(model, test, select = \"lambda.min\", type = \"response\")) #> # A tibble: 230 × 100 #>    boot1 boot2 boot3 boot4 boot5 boot6 boot7 boot8 boot9 boot10 boot11 boot12 #>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl> #>  1 0.784 0.732 0.747 0.687 0.669 0.684 0.783 0.717 0.675  0.763  0.643  0.768 #>  2 0.239 0.295 0.260 0.212 0.353 0.232 0.156 0.199 0.249  0.215  0.268  0.161 #>  3 0.644 0.600 0.482 0.595 0.523 0.646 0.700 0.566 0.555  0.696  0.581  0.661 #>  4 0.321 0.316 0.633 0.431 0.367 0.203 0.558 0.349 0.407  0.331  0.369  0.376 #>  5 0.239 0.259 0.283 0.253 0.335 0.262 0.308 0.265 0.215  0.264  0.242  0.285 #>  6 0.370 0.362 0.389 0.410 0.413 0.419 0.441 0.371 0.373  0.407  0.357  0.367 #>  7 0.958 0.931 0.903 0.858 0.865 0.873 0.893 0.860 0.861  0.931  0.874  0.862 #>  8 0.355 0.445 0.385 0.320 0.334 0.234 0.338 0.257 0.514  0.294  0.352  0.272 #>  9 0.427 0.517 0.508 0.505 0.426 0.378 0.480 0.426 0.644  0.460  0.481  0.393 #> 10 0.465 0.446 0.536 0.500 0.532 0.541 0.496 0.564 0.435  0.526  0.432  0.567 #> # ℹ 220 more rows #> # ℹ 88 more variables: boot13 <dbl>, boot14 <dbl>, boot15 <dbl>, boot16 <dbl>, #> #   boot17 <dbl>, boot18 <dbl>, boot19 <dbl>, boot20 <dbl>, boot21 <dbl>, #> #   boot22 <dbl>, boot23 <dbl>, boot24 <dbl>, boot25 <dbl>, boot26 <dbl>, #> #   boot27 <dbl>, boot28 <dbl>, boot29 <dbl>, boot30 <dbl>, boot31 <dbl>, #> #   boot32 <dbl>, boot33 <dbl>, boot34 <dbl>, boot35 <dbl>, boot36 <dbl>, #> #   boot37 <dbl>, boot38 <dbl>, boot39 <dbl>, boot40 <dbl>, boot41 <dbl>, … tibble(   predictions = rowMeans(     predict(model, test, select = \"lambda.min\", type = \"response\")   ) ) #> # A tibble: 230 × 1 #>    predictions #>          <dbl> #>  1       0.704 #>  2       0.254 #>  3       0.637 #>  4       0.372 #>  5       0.268 #>  6       0.395 #>  7       0.906 #>  8       0.328 #>  9       0.465 #> 10       0.470 #> # ℹ 220 more rows"},{"path":"/index.html","id":"fast-estimation-️","dir":"","previous_headings":"Usage","what":"Fast estimation 🏎️💨","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"bootstrapped model, bolasso uses cross-validation find optimal regularization parameter lambda. glmnet, default number cross-validation folds 10. can quickly become computationally expensive slow, especially using many bootstrap replicates. example, 1,000 bootstrap replicates, results estimating models 10,000 cross-validation sets. address , can activate fast = TRUE argument bolasso. Instead using cross-validation find optimal lambda bootstrap model, fast bolasso runs single cross-validated regression full dataset identify optimal lambda. bootstrapped model uses lambda regularization parameter. following comparison shows computation time standard bolasso vs fast bolasso across increasing bootstrap replicates. plot displays number seconds algorithm takes complete.  Fast bolasso clearly achieves pretty massive speedups standard version! difference speed accentuated estimating larger datasets.","code":"# Compare standard vs. fast bolasso across different bootstrap values times <- lapply(   c(10, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1e3),   \\(x) {     time_standard <- system.time({       bolasso(         diabetes ~ .,         data = train,         n.boot = x,         progress = FALSE,         family = \"binomial\"       )     })     time_fast <- system.time({       bolasso(         diabetes ~ .,         data = train,         n.boot = x,         progress = FALSE,         family = \"binomial\",         fast = TRUE       )     })     return(       tibble::tibble(\"regular\" = time_standard[[3]], \"fast\" = time_fast[[3]])     )   } )  # Make a data.frame out of the times times_df <- do.call(rbind, times) |>   transform(     id = 1:11,     n_bootstrap = c(10, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1e3)   ) |>   reshape(     varying = c(\"regular\", \"fast\"),     v.names = \"time\",     times = c(\"regular\", \"fast\"),     timevar = \"algorithm\",     idvar = c(\"id\", \"n_bootstrap\"),     direction = \"long\"   )  # Plot it! ggplot(times_df, aes(x = n_bootstrap, y = time, color = factor(algorithm))) +   geom_point() +   geom_line() +   labs(x = \"N Bootstraps\", y = \"Time (seconds)\") +   scale_y_continuous(breaks = seq(0, 60, 10)) +   theme_minimal() +   theme(legend.title = element_blank())"},{"path":"/index.html","id":"what-do-we-lose-with-standard-vs-fast","dir":"","previous_headings":"Usage > Fast estimation 🏎️💨","what":"What do we lose with standard vs. fast?","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"’s never free lunch, clear tradeoffs standard fast versions bolasso, following shows difference predictive accuracy hold-test set. ’s important note fast bolasso thought rough--ready algorithm better quick iteration might worse empirical performance standard algorithm.","code":"model_standard <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\" ) model_fast <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\",   fast = TRUE )  model_standard_preds <- ifelse(   rowMeans(predict(model_standard, test, type = \"response\")) >= 0.5,   yes = 1,   no = 0 ) model_fast_preds <- ifelse(   rowMeans(predict(model_fast, test, type = \"response\")) >= 0.5,   yes = 1,   no = 0 ) truth <- as.integer(test$diabetes) - 1 #> Standard Bolasso accuracy: 80.87 % #>  Fast Bolasso accuracy: 80.43 %"},{"path":"/index.html","id":"parallelizing-bolasso","dir":"","previous_headings":"Usage > Fast estimation 🏎️💨","what":"Parallelizing bolasso","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"can also fit bolasso bootstrap models parallel via future package. future package supports wide variety parallelization, local multi-core remote compute clusters. Parallelizing bolasso simple initializing parallel method prior executing bolasso function. example, following setup execute bolasso parallel R sessions.","code":"future::plan(\"multisession\") time_parallel <- system.time({   bolasso(     diabetes ~ .,     data = train,     n.boot = 1000,     progress = FALSE,     family = \"binomial\"   ) }) future::plan(\"sequential\")  time_sequential <- system.time({   bolasso(     diabetes ~ .,     data = train,     n.boot = 1000,     progress = FALSE,     family = \"binomial\"   ) }) #> Parallel bolasso time (seconds): 10.815  #> Sequential bolasso time (seconds): 42.909"},{"path":"/index.html","id":"beyond-the-lasso","dir":"","previous_headings":"Usage","what":"Beyond the Lasso","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"bolasso also allows us fit penalized regression models beyond Lasso. example, suppose want fit bootstrap-enhanced elasticnet model mixing parameter 0.5 (even mix Ridge Lasso regularization terms). can simply pass underlying glmnet::glmnet argument alpha = 0.5 bolasso. following code compares selected variables Lasso elasticnet models.","code":"lasso <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\" )  elnet <- bolasso(   diabetes ~ .,   data = train,   n.boot = 100,   progress = FALSE,   family = \"binomial\",   alpha = 0.5 ) #> Lasso selected variables: pregnant glucose mass age  #> Elnet selected variables: pregnant glucose mass pedigree age"},{"path":"/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Model Consistent Lasso Estimation Through the Bootstrap","text":"[1]Abram, Samantha V et al. “Bootstrap Enhanced Penalized Regression Variable Selection Neuroimaging Data.” Frontiers neuroscience vol. 10 344. 28 Jul. 2016, doi:10.3389/fnins.2016.00344 [2]Bach, Francis. “Bolasso: Model Consistent Lasso Estimation Bootstrap.” ArXiv:0804.1302 [Cs, Math, Stat], 2008. https://arxiv.org/abs/0804.1302. [3]Bunea, Florentina et al. “Penalized least squares regression methods applications neuroimaging.” NeuroImage vol. 55,4 (2011): 1519-27. doi:10.1016/j.neuroimage.2010.12.028","code":""},{"path":"/reference/bolasso.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootsrap-enhanced Lasso — bolasso","title":"Bootsrap-enhanced Lasso — bolasso","text":"function implements model-consistent Lasso estimation bootstrap. supports parallel processing way future package, allowing user flexibly specify many parallelization methods. method developed variable-selection algorithm, package also supports making ensemble predictions new data using bagged Lasso models.","code":""},{"path":"/reference/bolasso.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootsrap-enhanced Lasso — bolasso","text":"","code":"bolasso(   formula,   data,   n.boot = 100,   progress = TRUE,   implement = c(\"glmnet\", \"gamlr\"),   x = NULL,   y = NULL,   fast = FALSE,   ... )"},{"path":"/reference/bolasso.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootsrap-enhanced Lasso — bolasso","text":"formula optional object class formula (one can coerced class): symbolic description model fitted. Can omitted x y non-missing. data optional object class data.frame contains modeling variables referenced form. Can omitted x y non-missing. n.boot integer specifying number bootstrap replicates. progress boolean indicating whether display progress across bootstrap folds. implement character; either 'glmnet' 'gamlr', specifying Lasso implementation utilize. specific modeling details, see glmnet::cv.glmnet gamlr::cv.gamlr. x optional predictor matrix lieu form data. y optional response vector lieu form data. fast boolean. Whether fit \"fast\" bootstrap procedure. fast == TRUE, bolasso fit glmnet::cv.glmnet entire dataset. fit bootstrapped models value lambda (regularization parameter) minimized cross-validation loss full model. fast == FALSE (default), bolasso use cross-validation find optimal lambda bootstrap model. ... Additional parameters pass either glmnet::cv.glmnet gamlr::cv.gamlr.","code":""},{"path":"/reference/bolasso.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootsrap-enhanced Lasso — bolasso","text":"object class bolasso. object list length n.boot cv.glmnet cv.gamlr objects.","code":""},{"path":[]},{"path":"/reference/bolasso.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootsrap-enhanced Lasso — bolasso","text":"","code":"mtcars[, c(2, 10:11)] <- lapply(mtcars[, c(2, 10:11)], as.factor) idx <- sample(nrow(mtcars), 22) mtcars_train <- mtcars[idx, ] mtcars_test <- mtcars[-idx, ]  ## Formula Interface  # Train model set.seed(123) bolasso_form <- bolasso(   form = mpg ~ .,   data = mtcars_train,   n.boot = 20,   nfolds = 5 )  # Retrieve a tidy tibble of bootstrap coefficients for each covariate tidy(bolasso_form) #> # A tibble: 20 × 19 #>    id     Intercept   cyl4   cyl6   cyl8     disp       hp   drat     wt   qsec #>    <chr>      <dbl>  <dbl>  <dbl>  <dbl>    <dbl>    <dbl>  <dbl>  <dbl>  <dbl> #>  1 boot1      33.6  0.342  -0.541  0      0       -0.0251   0     -3.62  0.0901 #>  2 boot2      29.3  2.05    0     -1.07   0       -0.0155   0     -2.78  0      #>  3 boot3      29.6  5.55    0      0      0       -0.0173   0     -2.53  0      #>  4 boot4      44.2  0      -1.89   3.54   0       -0.0602   0     -4.11  0      #>  5 boot5      22.4  2.29    0      0      0       -0.00303  0     -3.98  0.577  #>  6 boot6      40.2  0.0442 -3.29   0      0       -0.0239   0     -5.21  0.133  #>  7 boot7       9.96 7.54    0     -3.86   0.0400   0        2.49  -2.16  0      #>  8 boot8      25.9  5.42    0      0     -0.0211   0        0     -0.841 0      #>  9 boot9      34.3  4.36    0      0      0.00763  0        0     -5.42  0.109  #> 10 boot10     36.0  5.00   -0.867  0      0        0        0     -4.79  0      #> 11 boot11     34.0  5.57    0      0      0       -0.0315  -0.671 -2.43  0      #> 12 boot12     30.4  4.20    0      0      0       -0.00637  0     -3.39  0      #> 13 boot13     33.6  2.02    0      0      0       -0.0122   0     -3.89  0      #> 14 boot14     34.1  2.95    0      0      0       -0.0267   0     -3.18  0      #> 15 boot15     31.6  2.07    0      0      0       -0.0170   0     -3.13  0      #> 16 boot16     38.5  1.89   -4.23   0      0.0158   0        0.581 -7.68  0.248  #> 17 boot17     33.7  3.84    0      0      0       -0.0223   0     -3.50  0      #> 18 boot18     43.9  0.395  -3.74   0      0       -0.0384   0     -4.97  0      #> 19 boot19     39.1  2.90   -1.74   0      0       -0.0294   0     -4.01  0      #> 20 boot20     22.0  3.85    0     -0.308  0       -0.00228  0     -4.36  0.648  #> # ℹ 9 more variables: vs <dbl>, am <dbl>, gear4 <dbl>, gear5 <dbl>, #> #   carb2 <dbl>, carb3 <dbl>, carb4 <dbl>, carb6 <dbl>, carb8 <dbl>  # Extract selected variables selected_variables(bolasso_form, threshold = 0.9, select = \"lambda.min\") #> # A tibble: 20 × 3 #>    id       cyl4     wt #>    <chr>   <dbl>  <dbl> #>  1 boot1  0.342  -3.62  #>  2 boot2  2.05   -2.78  #>  3 boot3  5.55   -2.53  #>  4 boot4  0      -4.11  #>  5 boot5  2.29   -3.98  #>  6 boot6  0.0442 -5.21  #>  7 boot7  7.54   -2.16  #>  8 boot8  5.42   -0.841 #>  9 boot9  4.36   -5.42  #> 10 boot10 5.00   -4.79  #> 11 boot11 5.57   -2.43  #> 12 boot12 4.20   -3.39  #> 13 boot13 2.02   -3.89  #> 14 boot14 2.95   -3.18  #> 15 boot15 2.07   -3.13  #> 16 boot16 1.89   -7.68  #> 17 boot17 3.84   -3.50  #> 18 boot18 0.395  -4.97  #> 19 boot19 2.90   -4.01  #> 20 boot20 3.85   -4.36   # Bagged ensemble prediction on test data predict(bolasso_form,         new.data = mtcars_test,         select = \"lambda.min\") #>                       boot1     boot2    boot3     boot4    boot5     boot6 #> Mazda RX4         22.136000 21.355411 21.65471 21.967038 21.12178 22.780565 #> Datsun 710        24.928046 27.496720 28.58999 28.930573 25.90059 29.181294 #> Duster 360        15.793256 13.717993 15.98303 15.357355 16.57274 17.812836 #> Merc 240D         22.679659 23.689025 25.98446 23.622992 23.33223 22.625793 #> Merc 280          19.005454 19.172257 18.41674 17.702542 18.87890 19.248354 #> Merc 450SLC       17.060371 16.829704 16.90419 17.391665 17.17946 17.918092 #> Chrysler Imperial  9.882457  9.014427 11.74785  8.959564 10.46209  9.129185 #> Toyota Corona     24.428651 25.191090 27.21624 28.093210 26.11878 28.516030 #> Camaro Z28        14.776491 12.967204 15.29944 14.246742 15.24961 16.348295 #> Fiat X1-9         27.026104 28.985211 30.03050 32.140456 27.68260 31.871866 #>                      boot7    boot8    boot9   boot10    boot11   boot12 #> Mazda RX4         19.24550 20.98732 22.61251 22.54044 21.980552 24.63474 #> Datsun 710        33.14551 28.60832 29.34080 30.45956 31.539419 30.81072 #> Duster 360        12.82984 15.34008 18.92005 18.85523 13.509988 16.71592 #> Merc 240D         29.75726 27.06058 22.34043 23.28057 24.354958 28.06333 #> Merc 280          17.82649 20.98565 18.80218 19.22500 17.507895 22.62863 #> Merc 450SLC       16.93580 16.93810 17.90399 17.84905 17.115417 16.41933 #> Chrysler Imperial 12.24004 12.16036 10.07738 10.35062  9.651028 10.80312 #> Toyota Corona     26.16696 27.59887 28.79879 29.76482 28.791991 26.45173 #> Camaro Z28        13.13997 15.32367 17.33309 17.56157 12.504033 15.80196 #> Fiat X1-9         33.39080 29.54351 31.23857 32.30423 33.172279 32.28603 #>                     boot13   boot14   boot15   boot16   boot17    boot18 #> Mazda RX4         22.07862 22.83754 21.49454 23.03257 22.09494 22.240705 #> Datsun 710        25.92231 27.20084 24.79358 31.42579 28.56655 29.236127 #> Duster 360        16.73828 16.20564 16.22302 22.57289 15.75047 16.072484 #> Merc 240D         22.91239 25.26060 22.02643 19.00373 24.06170 23.749863 #> Merc 280          19.18101 19.88035 18.70379 17.60249 20.13764 17.666961 #> Merc 450SLC       16.71130 17.27470 16.66956 18.84311 16.46770 18.243150 #> Chrysler Imperial 10.01055 10.95750 10.91523 10.60293  9.86899  7.830309 #> Toyota Corona     25.30916 26.63244 24.27119 30.76295 27.96931 28.361961 #> Camaro Z28        15.68715 15.34634 15.37686 20.53564 14.80482 14.731036 #> Fiat X1-9         27.74952 29.14782 26.45900 34.13086 30.51841 32.186810 #>                      boot19    boot20 #> Mazda RX4         21.946519 21.005058 #> Datsun 710        30.002143 27.594649 #> Duster 360        15.903332 15.847325 #> Merc 240D         23.546456 24.300253 #> Merc 280          18.273216 18.593329 #> Merc 450SLC       18.679698 16.479113 #> Chrysler Imperial  9.220408  9.169328 #> Toyota Corona     29.302575 27.860143 #> Camaro Z28        14.819687 14.392258 #> Fiat X1-9         32.341210 29.521835  ## Alternate Matrix Interface  # Train model set.seed(123) bolasso_mat <- bolasso(   x = model.matrix(mpg ~ . - 1, mtcars_train),   y = mtcars_train[, 1],   data = mtcars_train,   n.boot = 20,   nfolds = 5 )  # Bagged ensemble prediction on test data predict(bolasso_mat,         new.data = model.matrix(mpg ~ . - 1, mtcars_test),         select = \"lambda.min\") #>                       boot1     boot2    boot3     boot4    boot5     boot6 #> Mazda RX4         22.136000 21.355411 21.65471 21.967038 21.12178 22.780565 #> Datsun 710        24.928046 27.496720 28.58999 28.930573 25.90059 29.181294 #> Duster 360        15.793256 13.717993 15.98303 15.357355 16.57274 17.812836 #> Merc 240D         22.679659 23.689025 25.98446 23.622992 23.33223 22.625793 #> Merc 280          19.005454 19.172257 18.41674 17.702542 18.87890 19.248354 #> Merc 450SLC       17.060371 16.829704 16.90419 17.391665 17.17946 17.918092 #> Chrysler Imperial  9.882457  9.014427 11.74785  8.959564 10.46209  9.129185 #> Toyota Corona     24.428651 25.191090 27.21624 28.093210 26.11878 28.516030 #> Camaro Z28        14.776491 12.967204 15.29944 14.246742 15.24961 16.348295 #> Fiat X1-9         27.026104 28.985211 30.03050 32.140456 27.68260 31.871866 #>                      boot7    boot8    boot9   boot10    boot11   boot12 #> Mazda RX4         19.24550 20.98732 22.61251 22.54044 21.980552 24.63474 #> Datsun 710        33.14551 28.60832 29.34080 30.45956 31.539419 30.81072 #> Duster 360        12.82984 15.34008 18.92005 18.85523 13.509988 16.71592 #> Merc 240D         29.75726 27.06058 22.34043 23.28057 24.354958 28.06333 #> Merc 280          17.82649 20.98565 18.80218 19.22500 17.507895 22.62863 #> Merc 450SLC       16.93580 16.93810 17.90399 17.84905 17.115417 16.41933 #> Chrysler Imperial 12.24004 12.16036 10.07738 10.35062  9.651028 10.80312 #> Toyota Corona     26.16696 27.59887 28.79879 29.76482 28.791991 26.45173 #> Camaro Z28        13.13997 15.32367 17.33309 17.56157 12.504033 15.80196 #> Fiat X1-9         33.39080 29.54351 31.23857 32.30423 33.172279 32.28603 #>                     boot13   boot14   boot15   boot16   boot17    boot18 #> Mazda RX4         22.07862 22.83754 21.49454 23.03257 22.09494 22.240705 #> Datsun 710        25.92231 27.20084 24.79358 31.42579 28.56655 29.236127 #> Duster 360        16.73828 16.20564 16.22302 22.57289 15.75047 16.072484 #> Merc 240D         22.91239 25.26060 22.02643 19.00373 24.06170 23.749863 #> Merc 280          19.18101 19.88035 18.70379 17.60249 20.13764 17.666961 #> Merc 450SLC       16.71130 17.27470 16.66956 18.84311 16.46770 18.243150 #> Chrysler Imperial 10.01055 10.95750 10.91523 10.60293  9.86899  7.830309 #> Toyota Corona     25.30916 26.63244 24.27119 30.76295 27.96931 28.361961 #> Camaro Z28        15.68715 15.34634 15.37686 20.53564 14.80482 14.731036 #> Fiat X1-9         27.74952 29.14782 26.45900 34.13086 30.51841 32.186810 #>                      boot19    boot20 #> Mazda RX4         21.946519 21.005058 #> Datsun 710        30.002143 27.594649 #> Duster 360        15.903332 15.847325 #> Merc 240D         23.546456 24.300253 #> Merc 280          18.273216 18.593329 #> Merc 450SLC       18.679698 16.479113 #> Chrysler Imperial  9.220408  9.169328 #> Toyota Corona     29.302575 27.860143 #> Camaro Z28        14.819687 14.392258 #> Fiat X1-9         32.341210 29.521835  # Extract the indices of the bootstrap replicates bootstrap_samples(bolasso_mat) #> $boot1 #>  [1]  3  3  4  5  5  7  8  9  9 10 10 11 14 14 15 18 19 19 19 20 22 22 #>  #> $boot2 #>  [1]  2  5  6  7  7  7  8  9  9 10 10 11 12 12 13 13 14 15 17 21 21 21 #>  #> $boot3 #>  [1]  1  2  4  6  6  7  8  9 11 15 15 16 16 17 17 18 18 20 21 22 22 22 #>  #> $boot4 #>  [1]  3  3  3  5  5  7  8  8 12 13 14 14 14 15 16 19 19 20 21 22 22 22 #>  #> $boot5 #>  [1]  2  3  7  8 10 10 10 11 12 12 14 14 14 15 15 17 17 18 19 20 22 22 #>  #> $boot6 #>  [1]  2  4  5  6  6  7  7  7  9 10 11 12 13 14 14 16 16 19 19 20 21 22 #>  #> $boot7 #>  [1]  1  3  4  4  7  8  8  8 10 11 11 12 15 16 16 17 20 20 20 20 22 22 #>  #> $boot8 #>  [1]  1  2  4  6  8  8  8  8 10 11 12 13 13 13 14 14 14 16 18 21 21 21 #>  #> $boot9 #>  [1]  1  5  7  7  7  9  9  9 10 10 11 11 11 13 14 14 19 20 20 21 22 22 #>  #> $boot10 #>  [1]  1  1  1  2  3  4  5  6  6  7  9 10 10 14 17 17 17 18 20 20 21 21 #>  #> $boot11 #>  [1]  1  5  6  7  7  8  8  9 10 13 13 16 17 17 18 18 20 21 21 21 21 21 #>  #> $boot12 #>  [1]  2  2  2  3  3  3  3  4  5  6  6 10 10 10 12 13 13 16 16 17 17 18 #>  #> $boot13 #>  [1]  1  2  2  2  3  4  5  7  7  9  9  9 11 11 12 12 13 15 16 19 21 22 #>  #> $boot14 #>  [1]  3  3  6  6  8  8  9 10 10 12 13 15 16 17 17 18 18 19 20 20 20 22 #>  #> $boot15 #>  [1]  1  2  4  5  7  8 10 10 10 11 12 13 13 16 17 17 18 18 19 19 19 22 #>  #> $boot16 #>  [1]  1  1  2  3  4  6 11 12 12 12 14 15 15 16 16 16 17 18 19 19 21 21 #>  #> $boot17 #>  [1]  5  6  6  7  8  9  9 10 10 10 11 11 12 12 13 17 18 18 18 19 20 21 #>  #> $boot18 #>  [1]  3  4  4  4  4  6  6  7  8  9 10 10 14 15 16 16 17 19 20 20 21 22 #>  #> $boot19 #>  [1]  2  5  5  6  7  8  9 10 11 11 14 15 15 15 16 16 16 19 19 20 20 22 #>  #> $boot20 #>  [1]  2  3  5  6  6  6  7  8  8  8 10 11 14 14 15 15 17 17 18 19 20 21 #>"},{"path":"/reference/bootstrap_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract indices used for each bootstrap replicate — bootstrap_samples","title":"Extract indices used for each bootstrap replicate — bootstrap_samples","text":"function extracts indices used bootstrap data replicate. helpful additional analysis requires knowledge exact bootstrap samples used.","code":""},{"path":"/reference/bootstrap_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract indices used for each bootstrap replicate — bootstrap_samples","text":"","code":"bootstrap_samples(model)"},{"path":"/reference/bootstrap_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract indices used for each bootstrap replicate — bootstrap_samples","text":"model model class bolasso.","code":""},{"path":"/reference/bootstrap_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract indices used for each bootstrap replicate — bootstrap_samples","text":"named list length equal number bootstrap replicates contains corresponding indices used subsample data.","code":""},{"path":"/reference/plot.bolasso.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a bolasso object — plot.bolasso","title":"Plot a bolasso object — plot.bolasso","text":"method plots coefficient distributions covariates included bolasso model. 30 covariates included full model, plot 30 covariates largest absolute mean coefficient. user can also plot coefficient distributions specified subset covariates.","code":""},{"path":"/reference/plot.bolasso.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a bolasso object — plot.bolasso","text":"","code":"# S3 method for class 'bolasso' plot(x, covariates = NULL, ...)"},{"path":"/reference/plot.bolasso.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a bolasso object — plot.bolasso","text":"x object class bolasso bolasso_fast. covariates subset covariates plot. vector covariate names either strings bare. E.g. covariates = c(\"var_1\", \"var_2\") covariates = c(var_1, var_2). argument optional NULL default. case plot 30 covariates largest absolute mean coefficients. ... Additional arguments pass directly coef objects class bolasso bolasso_fast.","code":""},{"path":"/reference/plot_selected_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot selected variables from a bolasso object. — plot_selected_variables","title":"Plot selected variables from a bolasso object. — plot_selected_variables","text":"method plots coefficient distributions selected covariates bolasso model. 30 selected covariates, plot 30 selected covariates largest absolute mean coefficient. user can also plot coefficient distributions specified subset selected covariates.","code":""},{"path":"/reference/plot_selected_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot selected variables from a bolasso object. — plot_selected_variables","text":"","code":"plot_selected_variables(   x,   covariates = NULL,   threshold = 0.95,   method = c(\"vip\", \"qnt\"),   ... )"},{"path":"/reference/plot_selected_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot selected variables from a bolasso object. — plot_selected_variables","text":"x object class bolasso bolasso_fast. covariates subset selected covariates plot. vector covariate names either strings bare. E.g. covariates = c(\"var_1\", \"var_2\") covariates = c(var_1, var_2). argument optional NULL default. case plot 30 covariates largest absolute mean coefficients. threshold numeric 0 1, specifying variable selection threshold use. method variable selection method use. two valid options c(\"vip\", \"qnt\"). default \"vip\" method described original Bach (2008) complementary Bunea et al. (2011) works. \"qnt\" method method proposed Abram et al. (2016). ... Additional arguments pass coef objects class bolasso bolass_fast.","code":""},{"path":"/reference/plot_selection_thresholds.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot each covariate's smallest variable selection threshold — plot_selection_thresholds","title":"Plot each covariate's smallest variable selection threshold — plot_selection_thresholds","text":"Plot results selection_thresholds function.","code":""},{"path":"/reference/plot_selection_thresholds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot each covariate's smallest variable selection threshold — plot_selection_thresholds","text":"","code":"plot_selection_thresholds(object = NULL, data = NULL, ...)"},{"path":"/reference/plot_selection_thresholds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot each covariate's smallest variable selection threshold — plot_selection_thresholds","text":"object object class bolasso bolasso_fast. argument optional directly pass data via data argument. E.g. data = selection_thresholds(object). data dataframe containing selection thresholds. E.g. obtained via selection_thresholds(object). argument optional directly pass bolasso bolasso_fast object via object argument. ... Additional arguments pass directly selection_thresholds.","code":""},{"path":"/reference/plot_selection_thresholds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot each covariate's smallest variable selection threshold — plot_selection_thresholds","text":"ggplot object","code":""},{"path":[]},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics tidy","code":""},{"path":"/reference/selected_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Bolasso-selected Variables — selected_variables","title":"Bolasso-selected Variables — selected_variables","text":"Identifies covariates selected Bolasso algorithm user-defined threshold. two variable selection criterion choose ; Variable Inclusion Probability (\"vip\") introduced original Bolasso paper (Bach, 2008) developed Bunea et al. (2011), Quantile (\"qnt\") approach proposed Abram et al. (2016). desired threshold value 1 - alpha, alpha (typically small) significance level.","code":""},{"path":"/reference/selected_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bolasso-selected Variables — selected_variables","text":"","code":"selected_variables(   object,   threshold = 0.95,   method = c(\"vip\", \"qnt\"),   var_names_only = FALSE,   ... )"},{"path":"/reference/selected_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bolasso-selected Variables — selected_variables","text":"object object class bolasso. threshold numeric 0 1, specifying variable selection threshold use. method variable selection method use. two valid options c(\"vip\", \"qnt\"). default \"vip\" method described original Bach (2008) complementary Bunea et al. (2011) works. \"qnt\" method method proposed Abram et al. (2016). var_names_only boolean value. var_names_only = FALSE (default value) function return tibble::tibble selected covariates corresponding coefficients across bootstrap replicates. var_names_only == TRUE, return vector containing selected covariate names. ... Additional arguments pass coef objects class bolasso bolass_fast.","code":""},{"path":"/reference/selected_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bolasso-selected Variables — selected_variables","text":"tibble selected variable respective coefficient bootstrap replicate vector names selected variables.","code":""},{"path":"/reference/selected_variables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bolasso-selected Variables — selected_variables","text":"function returns either tibble::tibble selected covariates corresponding coefficients across bootstrap replicates, vector selected covariate names.","code":""},{"path":[]},{"path":"/reference/selection_thresholds.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate each covariate's smallest variable selection threshold — selection_thresholds","title":"Calculate each covariate's smallest variable selection threshold — selection_thresholds","text":"two methods variable selection covariates. first Variable Inclusion Probability (VIP) introduced Bach (2008) generalized Bunea et al (2011). second Quantile confidence interval (QNT) proposed Abram et al (2016). given level significance alpha, method selects covariates given threshold = 1 - alpha. higher threshold (lower alpha), stringent variable selection criterion.","code":""},{"path":"/reference/selection_thresholds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate each covariate's smallest variable selection threshold — selection_thresholds","text":"","code":"selection_thresholds(object, grid = seq(0, 1, by = 0.01), ...)"},{"path":"/reference/selection_thresholds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate each covariate's smallest variable selection threshold — selection_thresholds","text":"object object class bolasso bolasso_fast. grid vector numbers 0 1 (inclusive) specifying grid threshold values calculate variable inclusion criterion . Defaults seq(0, 1, = 0.01). ... Additional parameters pass coef objects class bolasso bolasso_fast.","code":""},{"path":"/reference/selection_thresholds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate each covariate's smallest variable selection threshold — selection_thresholds","text":"tibble dimension (2*p)x5 p number covariates.","code":""},{"path":"/reference/selection_thresholds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate each covariate's smallest variable selection threshold — selection_thresholds","text":"function returns tibble , covariate, returns largest threshold (equivalently smallest alpha) selected VIP QNT methods. Consequently number rows returned tibble 2*p p number covariates included model.","code":""},{"path":"/reference/tidy.bolasso.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a bolasso object — tidy.bolasso","title":"Tidy a bolasso object — tidy.bolasso","text":"Tidy bolasso object","code":""},{"path":"/reference/tidy.bolasso.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a bolasso object — tidy.bolasso","text":"","code":"# S3 method for class 'bolasso' tidy(x, select = c(\"lambda.min\", \"lambda.1se\", \"min\", \"1se\"), ...)"},{"path":"/reference/tidy.bolasso.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a bolasso object — tidy.bolasso","text":"x bolasso object. select One \"min\", \"1se\", \"lambda.min\", \"lambda.1se\". \"min\" \"lambda.min\" equivalent lambda value minimizes cv MSE. Similarly \"1se\" \"lambda.1se\" equivalent refer lambda achieves regularization within 1se minimal cv MSE. ... Additional arguments pass directly coef.bolasso.","code":""},{"path":"/reference/tidy.bolasso.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy a bolasso object — tidy.bolasso","text":"tidy tibble::tibble() summarizing bootstrap-level coefficients covariate.","code":""},{"path":"/reference/transactions.html","id":null,"dir":"Reference","previous_headings":"","what":"Customer transaction data — transactions","title":"Customer transaction data — transactions","text":"Predict whether customers make specific transaction based rich set user features.","code":""},{"path":"/reference/transactions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Customer transaction data — transactions","text":"","code":"transactions"},{"path":"/reference/transactions.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Customer transaction data — transactions","text":"Dataframe columns target integer indicating whether customer engaged transaction. var_i 200 numeric features various customer characteristics.","code":""},{"path":"/news/index.html","id":"bolasso-040","dir":"Changelog","previous_headings":"","what":"bolasso 0.4.0","title":"bolasso 0.4.0","text":"Allows user extract bootstrap indices bootstrap_samples().","code":""},{"path":"/news/index.html","id":"bolasso-030","dir":"Changelog","previous_headings":"","what":"bolasso 0.3.0","title":"bolasso 0.3.0","text":"CRAN release: 2024-12-08","code":""},{"path":"/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"bolasso 0.3.0","text":"bolasso() gains fast argument optimizes computation using single cross-validated regression entire dataset determine optimal regularization parameter (lambda). approach bypasses need cross-validation within bootstrap replicate, drastically reducing computation time, especially beneficial large datasets using high number bootstrap replicates. selected_vars() now shorthand selected_variables(). selected_variables()/selected_vars() supports two variable selection algorithms via method argument: Variable Inclusion Probability (VIP) method Quantile (QNT) method. VIP method selects variables appear high percentage bootstrap models, QNT method selects variables based bootstrap confidence intervals. Set method = \"vip\" method = \"qnt\", respectively. tidy() extracts tidy tibble summarizing bootstrap-level coefficients covariate. method provides clean organized way inspect model coefficients. plot_selection_thresholds() provides visual representation selection thresholds variable. visualization helps users understand stability robustness variable selection across different thresholds methods.","code":"# Fast mode reduces computation time by using a single cross-validated lambda model_fast <- bolasso( diabetes ~ ., data = train, n.boot = 1000, progress = FALSE, family = \"binomial\", fast = TRUE ) # Select variables using the VIP method with a 95% threshold selected_vars_vip <- selected_variables(model, threshold = 0.95, method = \"vip\")  # Select variables using the QNT method selected_vars_qnt <- selected_variables(model, threshold = 0.95, method = \"qnt\") # Extract a tidy tibble of coefficients tidy_coefs <- tidy(model, select = \"lambda.min\") # Visualize selection thresholds for variables plot_selection_thresholds(model, select = \"lambda.min\")"},{"path":"/news/index.html","id":"improvements-0-3-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"bolasso 0.3.0","text":"plot_selected_variables() visualizes coefficient distributions selected variables. function provides focused view relevant variables model. plot visualizes coefficient distributions model covariates.","code":"# Plot coefficient distributions for selected variables plot_selected_variables( model, threshold = 0.95, method = \"vip\", select = \"lambda.min\" ) # Plot coefficient distributions for selected variables plot(model, select = \"lambda.min\")"},{"path":"/news/index.html","id":"bolasso-020","dir":"Changelog","previous_headings":"","what":"bolasso 0.2.0","title":"bolasso 0.2.0","text":"CRAN release: 2022-05-09 Added NEWS.md file track changes package. bolasso() argument form renamed formula reflect common naming conventions R statistical modeling packages. predict() coef() methods now implemented using future.apply::future_lapply allowing computing predictions extracting coefficients parallel. may result slightly worse performance (due memory overhead) model/prediction data small significantly faster e.g. generating predictions large data-set. Solved issue bolasso() argument formula. user-supplied value formula handled via deparse() default width.cutoff value 60. causing issues formulas splitting multi-element character vectors. now set maximum value 500L correctly parse lengths formulas. predict() now forces evaluation formula argument bolasso() call. resolves issue , user passes formula via variable, predict() pass variable name underlying prediction function opposed actual formula.","code":""}]
